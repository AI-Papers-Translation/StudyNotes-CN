# C02. 学习基础与线性模型

## 2.1 有监督学习和参数化函数

有监督机器学习：通过观测样例进而产生泛化的机制。

-   设计算法，算法的输入是一组有标注的样例，输出是一个接收实例、产生期望标签的函数。对于在训练时没有见过的样例，最终函数也可以产生预测标签
-   搜索所有可能的函数是困难的，于是把函数限制在特定的函数簇内，这样的函数簇称作假设类。通过把搜索限制在假设类之中，学习器中引入了归纳偏置——一组关于期望结果形式的假设，同时也使得搜索结果的过程更加高效。
-   假设类确定了学习器可以表示什么，不可以表示什么
    -   常见的假设类：高维线性函数。$f(\text{x})=\text{x}\cdot\text{W}+\text{b}, \text{x}\in\mathbb{R}^{d_{in}}, \text{W}\in\mathbb{R}^{d_{in}\times d_{out}}, \text{b}\in\mathbb{R}^{d_{out}}$
        -   $\text{x}$ 表示函数的输入
        -   $\text{W,b}$ 表示函数的参数
    -   线性模型的性质
        -   训练简单高效
        -   通常会得到凸优化目标
        -   训练得到的模型具备可解释性
    -   具有隐层的前馈神经网络也是参数化函数，构成了更加强大的假设：是通用近似器，可以表示任意的 Borel 可测函数

## 2.2 训练集、测试集和验证集

留一法

-   留一交叉验证(Leave One out Cross-Validation)：训练$k$ 个函数 $f_{1,k}$，每次取出一个不同的输入样例 $\text{x}_i$，评价得到的函数 $f_i()$ 预测 $\text{x}_i$ 的能力，<!--TODO:最后将所有的预测结果的平均？-->

留存集

-   在较大的子集(训练集)上训练模型
-   在较小的子集(留存集，Held-Out Set)上测试模型的准确率。

三路划分

-   训练集
-   验证集(开发集)：所有的实验、调参、误差分析和模型选择都在验证集上完成
-   测试集：测试集上的一次评测确定模型的质量，因此需要保证测试集尽可能纯洁

## 2.3 线性模型

<!--TODO:待填充-->

## 2.4 表示

训练模型，并且将之应用到一个文档得到的向量就是这个文档的表示(Representation)，因为向量抓住了文档的重要属性。表示更加紧凑，更加针对语言预测对象。

表示是深度学习的核心。深度学习的主要能力就是学习好的表示能力。

-   在线性情况下，表示是可以理解的。可以为表示向量的每个维度指派一个有意义的解释。
-   在深度学习下，表示是不可理解的，但是对于预测依然是有用的。
    -   在模型的边界上，可以得到输入和输出的特定方面的表示 [Sec 8.3](Ch08.md)

## 2.5 独热向量表示和稠密向量表示

词袋(Bag of Words，BOW)，称作平均二元对词袋(Averaged Bag of Bigrams)，或者叫平均词袋(Averaged Bag of Words)，表示包含文档中所有单词的不考虑次序的个性信息。

独热向量表示：可以被认为是单一单词的词袋。

连续单词词袋(Continuous Bag of Words，CBOW)：由低维度连续向量的单词表示的总和组成。表示可以通过求单词表示向量的和 或者  通过将一个单词词袋向量乘以一个每一行对应于一个稠密单词表示的矩阵(这个矩阵是嵌入矩阵)来得到。

