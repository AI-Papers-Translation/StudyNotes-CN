# C02. 基于 Bayes 决策理论的分类器

## 2.1 引言

设计分类器将未知类型的样本分类到最可能的类别中。

前提条件

-   $M$ 个类别 {$\omega_1,\cdots,\omega_M$}
-   用特征向量 $\text{x}$ 表示的未知样本

计算结果

-   生成 $M$ 个条件概率 $P(\omega_i|\text{x}),i=1,\cdots,M$，也称为后验概率，也就是对于特征向量 $\text{x}$ 每一项都代表未知样本属于某一特定类 $\omega_i$ 的概率

## 2.2 Bayes 决策理论

二分类问题

-   前提条件
    -   样本类别 $\omega_1,\omega_2$
    -   $N$ 是训练样本的总数
        -   $N_1$ 是类别属于 $\omega_1$ 的训练样本的数目
        -   $N_2$ 是类别属于 $\omega_2$ 的训练样本的数目
    -   先验概率 $P(\omega_1),P(\omega_2)$
        -   $P(\omega_1)\sim N_1/N$
        -   $P(\omega_2)\sim N_2/N$
    -   概率密度函数 $p(\text{x}|\omega_i)$ 是相对于 $\text{x}$ 的 $\omega_i$ 的似然函数
        -   隐含的假设：特征向量可以是 $l$ 维空间中的任何值，即特征向量可以取任何离散值，密度函数 $p(\text{x}|\omega_i)$ 就变成了概率，可以表示为 $P(\text{x}|\omega_i)$
    -   Bayes 规则
        -   $P(\omega_i|\text{x})=\frac{p(\text{x}|\omega_i)P(\omega_i)}{p(\text{x})}$
        -   $p(\text{x})=\sum_{i=1}^2 p(\text{x}|\omega_i)P(\omega_i)$
-   Bayes 分类规则
    -   如果 $P(\omega_1|\text{x})>P(\omega_2|\text{x})$，则 $\text{x}$ 属于 $\omega_1$
    -   如果 $P(\omega_1|\text{x})<P(\omega_2|\text{x})$，则 $\text{x}$ 属于 $\omega_2$
    -   如果 $P(\omega_1|\text{x})=P(\omega_2|\text{x})$，则 $\text{x}$ 无法判断
    -   错误率(Fig 2.1) $P_e =\frac12 (\int_{-\infty}^{x_0} p(\text{x}|\omega_2)\text{dx}+\int_{x_0}^{+\infty} p(\text{x}|\omega_1)\text{dx})$

-   Bayes 分类器在最小化分类错误率上是最优的
    -   <!--TODO:补充证明过程-->
-   基于「损失」最小化平均风险
    -   惩罚系数 $\lambda_{ki}$ 表示属于 $\omega_k$ 的特征向量被错误分到 $\omega_i$ 所产生的损失
        -   由惩罚系数组成的矩阵 $L$ 称为损失矩阵
    -   与 $\omega_k$ 相关的风险或者损失定义为 $r_k=\sum_{i=1}^M \lambda_{ki}\int_{R_i} p(\text{x}|\omega_k)\text{dx}$
    -   平均风险 $r=\sum_{k=1}^M r_k P(\omega_k)=\sum_{i=1}^M \int_{R_i} \biggl(\sum_{k=1}^M \lambda_{ki} p(\text{x}|\omega_k)P(\omega_K)\biggl)\text{dx}$
        -   选择合适的 $R_i$ 使得 $r$ 最小，必须使每个部分都最小
        -   分区选择 $\text{x}\R_i, l_i\equiv\sum_{k=1}^M \lambda_{ki}p(\text{x}|\omega_k)P(\omega_k)<l_j$
        -   <!--TODO:待完善-->
        -   最小化平均风险就等价于最小化分类错误率