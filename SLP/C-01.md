# C01. 统计学习方法概论

-   这一章都是概念和结论，如果读者能够透过概念就明白里面实际操作的内容，那就可以快速浏览此书，否则准备纸和笔认真精读方能收获。
-   后面的各章内容相对独立，读者既可以连续学习，也可以仅选择自己感兴趣的内容。

## 统计学习

### 统计学习导言

-   统计学习 (statistical learning): 计算机基于数据构建概率统计模型，并运用模型对数据进行预测与分析的一门学科。
    -   因此统计学习也称为统计机器学习 (statistical machine learning).
-   统计学习的主要特点
    -   理论基础
        -   数学基础 : 微积分、线性代数、概率论、统计学、计算理论、最优化理论
        -   其他基础 : 信息论、计算机科学及应用相关的科学等多个领域的交叉学科
        -   在发展中形成自己独立的理论体系与方法论。
    -   应用基础 : 计算机及网络；
    -   研究对象 : 数据，是数据驱动的学科；
    -   研究目的 : 对数据进行分类和预测；
    -   研究手段 : 通过统计学习方法构建模型，并应用模型进行分类和预测；

### 统计学习的对象

-   统计学习的对象是数据 (data)
    -   从数据出发，提取数据的 “特征” ，抽象出数据的 “模型” ，发现数据中的 “知识” ，又回到对数据的 “分类” 与 “预测” 中。
    -   数据的基本假设 : 同类数据具有一定的统计规律性，所以可以用概率统计方法加以处理。
    -   数据分类有 "连续型" 和 "离散型" 两种，本书主要关注的是 "离散型" 数据。

### 统计学习的目的

-   模型 : 学习什么样的模型
-   策略 : 如何学习模型 → 使模型能够对数据进行准确地分类和预测
-   算法 : 如何提高模型的学习效率

### 统计学习的方法

-   **统计学习的方法分类**
    -   **有监督学习 (supervised learning)** ( 全书重点 )
        -   从给定的、有限的、用于学习的训练数据 (training data) 集合出发；
            -   假设数据是独立同分布产生的；
        -   假设要学习的模型属于某个函数的集合，称为假设空间 (hypothesis space);
        -   基于某个评价标准 (evaluation criterion), 从假设空间中选取一个最优的模型
            -   使模型在给定的评价准则下，对已知训练数据及未知测试数据 (test data) 都有最优的预测；
        -   最优模型的选取都由算法实现。
    -   无监督学习 (unsupervised learning):
    -   半监督学习 (semi-supervised learning):
    -   强化学习 (reinforcement learning):
-   统计学习方法的三个要素
    -   模型 (model): 模型的假设空间；
    -   策略 (strategy): 模型选择的准则；
    -   算法 (algorithm): 模型学习的算法。
-   实现统计学习方法的步骤
    -   得到一个有限的、用于训练的数据集合；
    -   模型的集合 : 确定包含所有可能的模型的假设空间；
    -   学习的策略 : 确定模型选择的准则；
    -   学习的算法 : 确定求解最优模型的算法；
    -   通过学习的方式选择出最优模型；
    -   利用学习的最优模型对新数据进行分类或预测。
-   统计学习中的有监督学习根据 "解决的问题" 主要包括
    -   **分类问题** : 判别模型，处理离散数据
    -   **预测问题** : 回归模型，处理连续数据
    -   标注问题 : 既是分类问题的推广，又是预测问题的简化。

### 统计学习的研究

-   统计学习方法 (statistical learning method): 开发新的学习方法；
-   统计学习理论 (statistical learning theory): 探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；
-   统计学习应用 (application of statistical learning): 将统计学习方法应用到实际问题中去，解决实际问题。

### 统计学习的重要性

-   是处理海量数据的有效方法；
-   是计算机智能化的有效手段；
-   是计算机科学发展的重要组成。

## **监督学习**

-   监督学习的任务 : 是学习一个模型，使模型能够对任意给定的输入，及其相应的输出做出一个好的预测

### 基本概念

-   输入空间 : 输入数据所有可能取值的集合；集合中元素的个数可以有限，也可以是整个空间；
-   输出空间 : 输出数据所有可能取值的集合；集合中元素的个数可以有限，也可以是整个空间；
-   假设空间 : 由输入空间到输出空间的映射的集合，即可供选择的模型构成的空间；
-   特征空间 : 所有特征向量存在的空间。
    -   每个具体的输入是一个实例 (instance), 通常由特征向量 (feature vector) 表示。
-   统计学习中的有监督学习根据 "输入变量" 和 "输出变量" 的不同主要包括
    -   分类问题 : 输出变量为有限个离散变量的预测问题；
    -   回归问题 : 输入变量与输出变量均为连续变量；
    -   标注问题 : 输入变量与输出变量均为变量序列的预测问题；
-   联合概率分布 : 输入变量与输出变量遵循联合分布；

### 问题的形式化描述

-   在学习过程中，学习系统 ( 也就是学习算法 ) 试图通过给定的训练数据集合中的样本带来的信息来学习得到模型。

## 统计学习三个要素

-   统计学习方法 = 模型 + 策略 + 算法

### 模型

-   主要问题 : 学习什么样的模型？
-   模型的假设空间 : 包含所有可能的条件概率分布或决策函数，即由一个参数向量决定的函数族，也称为参数空间 (parameter space)。
-   模型分类
    -   非概率模型 : 由决策函数表示的模型；
    -   概率模型 : 由条件概率表示的模型；

### 策略

-   主要问题 : 按照什么样的准则，学习得到最优的模型，或者从假设空间中选择最优的模型。
-   基本概念
    -   损失函数 (loss function) 或代价函数 (cost function): 度量模型一次预测的好坏；
    -   风险函数 (risk function) 或期望损失 (expected loss): 度量平均意义下模型预测的好坏。
    -   经验风险 (empirical risk) 或经验损失 (empirical loss): 表示模型与训练数据的破例程度，即模型训练样本集的平均损失，当样本容量趋于无穷时，经验风险逼近期望风险；
    -   结构风险 (structural risk): 表示模型先验知识，例如 : 模型复杂度的正则化项 (regularizer) 或惩罚项 (penalty term)。
-   常用的损失函数
    -   0-1 损失函数
    -   平方损失函数
    -   绝对值损失函数
    -   对数损失函数或对数似然损失函数
-   学习目标
    -   理想状态 : 就是选择期望风险或期望损失最小的模型，希望可以提供无限的数据训练；
    -   现实状态 : 就是选择经验风险或经验损失最小的模型，因为只能提供有限的数据训练；
-   经验风险矫正 : 当样本容量过小时，容易出现 "过拟合" 问题，所以需要对经验风险进行矫正，经验风险最小化 + 结构风险最小化
    -   经验风险最小化 (empirical risk minimization, ERM): 极大似然估计
    -   结构风险最小化 (structural risk minimization, SRM): 最大后验估计

### 算法

-   统计学习是基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。
-   **算法** 即计算方法。统计学习的算法就转化为求解最优化问题的算法。
    -   有显式的解析解的最优化问题；
    -   无显式的解析解的最优化问题，需要用数值计算的方法求解。
        -   如何保证找到全局最优解；
        -   如何保证求解的过程高效。

## 模型的评估与选择

-   1.4~1.7, 与模型选择有关的问题。
-   1.8~1.10, 与模型应用有关的问题。

### 模型评估

-   学习方法评估的标准
    -   基于损失函数的模型的训练误差 (training error): 用来评估一个学习问题是否容易学习
    -   基于损失函数的模型的测试误差 (test error): 用来评估一个模型是否具备更有效的预测
-   泛化能力 (generalization ability): 学习方法对未知数据的预测能力

### 模型选择

-   过拟合 (over-fitting): 学习时选择的模型所包含的参数过多，以至于模型对已知数据预测较好，未知数据预测较差的问题
-   模型选择的常用方法
    -   正则化
    -   交叉验证

## 正则化与交叉验证

### 正则化

-   正则化 (regularization): 结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。
    -   正则化项一般是模型复杂度的单调递增函数。
        -   复杂度定义可以参考 Kolmogorov 复杂性理论 (complexity theory) [^Haykin,2011] P48
    -   Occam 剃刀原理 : 应用于模型选择时符合正则化的想法，即所有能够解释数据的模型中，复杂度越小越好。
    -   Bayes 估计 : 正则化项对应于模型的先验概率。数据较少时先验概率就可以抑制数据中噪声的干扰，防止出现过拟合问题。数据很多时，先验概率就让位于数据对模型的解释。
    -   正则化是优化学习算法，调整目标函数，增加先验知识的重要手段，是机器学习的核心之一。
        -   简单了解 : [^周志华，2018] P133
        -   深入理解 : [^Haykin,2011] C07

### 交叉验证

-   交叉验证 (cross validation)
    -   在数据充足时，随机地将数据切分成三个部分 : 训练集、验证集和测试集。
        -   选择对验证集有最小预测误差的模型。
    -   训练集 (training set): 用来训练模型；
    -   验证集 (validation set): 用来选择模型；
    -   测试集 (test set): 用来评估模型。
-   交叉验证的常用方法
    -   简单交叉验证 : 随机地将数据分成两个部分，70% 的数据为训练集，30% 的数据为测试集，选择测试误差最小的模型；
    -   S 折交叉验证
        -   随机地将数据分成 S 个互不相交的大小相同的部分
        -   然后利用 S-1 个部分的数据训练，1 个子集测试模型，
        -   再将这一个过程对所有可能的选择重复进行，
        -   最后选择 S 次评测中平均测试误差最小的模型。
    -   留一交叉验证 : 当 S=N 时采用的 S 折交叉验证，适用于数据极度缺乏的情况下。(N 为给定数据集的容量 )

## 泛化能力

### 泛化误差

-   泛化能力 (generalization ability): 是指学习方法学习到的模型对未知数据的预测能力
-   泛化误差 (generalization error): 是指学到的模型对未知数据预测产生的误差，反映了学习方法的泛化能力。

### 泛化误差的上界

-   泛化误差的上界 (generalization error bound): 泛化误差的概率上界，通过比较两种学习方法的泛化误差概率上界来确定优劣
-   泛化误差上界的性质
    -   是样本容量的函数，当样本容量增加时，泛化上界趋向于 0;
    -   是假设空间的函数，当假设空间容量增加时，泛化误差上界就会变大，表示模型就更加难学。
-   _泛化误差上界定理及证明_ ( 建议跳过 )

## 生成模型与判别模型

-   生成模型 (generative model): 模型表示了给定输入 X 产生输出 Y 的生成关系。
    -   特点
        -   还原出联合概率分布；
        -   学习收敛速度快；
        -   样本容量增加时，能够更好地逼近真实模型；
        -   存在隐变量时，仍然可以使用。
    -   应用 : 朴素 Bayes 方法和隐马尔可夫模型 (Hidden Markov Model, HMM);
    -   注 : 生成模型是比较难理解的概念，HMM 是理解生成模型比较好的途径，如果对 HMM 感兴趣可以参考
        -   简单了解 : [^周志华，2018] ( P 320 )
        -   深入理解 : [^Rabiner,1989]
-   判别模型 (discriminative model): 由数据直接学习决策函数或者条件概率分布作为预测的模型
    -   特点
        -   直接学习得到条件概率分布或者决策函数；
        -   直接面对预测，学习的准确率更高；
        -   基于参数是直接学习得到的，因此可以对数据进行各种程度上的抽象、定义和使用特征，简化学习问题。
    -   应用 : k 近邻法、感知机、决策树、Logistic 回归模型、最大熵模型、支持向量机、提升方法和条件随机场等

## 分类问题

-   分类器 (classifier): 监督学习从数据中学习得到的分类模型或分类决策函数。
-   分类 (classification): 利用分类器对新输入的数据进行输出的预测。
-   解决分类问题的两个过程
    -   学习过程 : 根据已知的训练数据集利用有效的“学习方法”得到一个分类器；
    -   分类过程 : 利用学习得到的分类器对新输入的实例进行分类。
-   评价分类器性能的指标 : 分类准确率 (accuracy), 即对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。
    -   二类分类问题常用的评价指标 : 精确率 (precision) 与召回率 (recall)。
-   解决分类问题的常用方法 : k 近邻法、感知机、朴素 Bayes 法，决策树、决策列表、Logistc 回归模型、支持向量机、提升方法等

## 标注问题

-   标注问题 : 是分类问题的推广，也是更复杂的结构预测问题的简单形式。
    -   输入是一个观测序列；
    -   输出是一个标记序列或状态序列。
    -   目标是通过学习得到能够对观测序列给出标记序列作为预测的模型。
-   解决标注问题的两个过程 : 学习过程 和 标注过程
-   评价标注问题的指标 : 准确率、精确率和召回率。
-   解决标注问题的常用方法 : 隐 Markov 模型和条件随机场。

## 回归问题

-   回归 (regression): 用于预测输入变量 ( 自变量 ) 和输出变量 ( 因变量 ) 之间的关系。
-   回归模型 : 表示从输入变量到输出变量之间的映射关系的函数。
    -   等价于 : 函数拟合。
-   解决回归问题的两个过程 : 学习过程和预测过程。
-   回归问题的分类
    -   按输入变量的个数 : 一元回归和多元回归；
    -   按输入变量和输出变量之间的关系 : 线性回归和非线性回归。
-   回归学习最常用的损失函数 : 平方损失函数，求解平方损失函数可以用最小二乘法。