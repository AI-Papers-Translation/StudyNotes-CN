# C09. EM 算法及推广

-   学习基础
    -   概率论 : 期望
    -   最大似然估计或极大后验估计
    -   梯度下降
-   EM 算法是对含有隐变量的概率模型进行极大似然估计或者极大后验估计的迭代算法。
    -   E 步，求期望；利用数据和假设的初值，求得一个隐变量的条件概率分布的期望，即 “Q 函数”。 ( 因为无法求得条件概率分布的具体值 )
    -   M 步，求极值。利用 “Q 函数” 来求极值，这个极值可以帮助拟合的概率分布更加逼近真实分布。
    -   **Q 函数的定义** ( 理解 Q 函数的涵义可以更好地推广到应用中，开始不理解也没关系，可以在应用中慢慢加深 )
    -   **EM 算法的推导** ( 如果书上的无法理解，还可以参考本文中的其他文献 )
        -   EM 算法是收敛的，但是有可能收敛到局部最小值。
        -   EM 算法可以看成利用凸函数进行概率密度逼近；
        -   如果原概率密度函数有多个极值，初值的不同就可能逼近到不同的极值点，所以无法保证全局最优。
    -   EM 算法的应用 ( 下面的两个应用都是重点，但是无法从本书中完全理解，可以在未来的应用继续探索 )
        -   **高斯混合模型**
        -   **HMM(隐Markov模型)** ( Ch 10 )
    -   _EM 算法的推广_ ( 建议跳过，对了解 EM 算法帮助不大，只有深入理解和研究 EM 算法才需要 )
        -   F 函数的极大 - 极大算法
        -   广义 EM 算法 ( GEM )
-   **学习总结**
-   EM 算法的详细推导。[^Borman,2004], 或者 Determined22 的 [EM 算法简述及简单示例(三个硬币的模型)](http://www.cnblogs.com/Determined22/p/5776791.html)
-   EM 算法的概率分析。[^Friedman,2001], 或者苏剑林的 [梯度下降和 EM 算法](https://spaces.ac.cn/archives/4277)
-   EM 算法的深入理解。可以参考史春奇的 [Hinton 和 Jordan 理解的 EM 算法](https://www.jianshu.com/p/bfa6b5947cd9)

