# 全书总评

## 书本印刷质量 : 4 星

印刷清楚，排版合适，错误很少。

<!-- TODO: -->

## 著作编写质量 : 4 星

自学机器学习的必备。

-   优点
        -   全书一直围绕着统计学习中的有监督学习描述，内容不深，基本算法都有所介绍；
        -   内容的组织是从抽象到具体的思维模式，比国外的教材易于理解；
        -   是自学统计学习和机器学习的推荐用书。
-   缺点
    -   基础部分讲解缺少理论，学完后无法理解，不利用学以致用。例如 : 感知器的损失函数，应该是统计学习的核心思想，那么损失函数在整个算法中的位置，以及如何选择损失函数都需要说明清楚，才能够指导后面各种其他机器学习方法的理解。
    -   使用的方法没有导入的原因和出处，学习过程中会产生比较大的跳跃感，延续性不足。例如 : 随机梯度下降法，只是说明用于神经网络的优化需要用随机梯度下降，而实际上随机梯度下降是为了满足在线学习的需要，如果是批量学习可以直接使用梯度学习算法实现。
-   总结 : 瑕不掩瑜，建议结合 “西瓜书” [^周志华，2018] 一起看。

## 读书建议

<!-- TODO: 重点，概念，公式，算法-->

笔记目的 : 记录重点，方便回忆。

# 重要的数学符号与公式

建议将下面列出的重要的数学符号与公式找张纸列在上面，方便在后面看到时可以查询。

## 重要的数学符号

-   $\mathbf{x}= ( x_1,x_2,\dots,x_D )^T$：表示$D$维向量
-   $\mathbf{X}=[\mathbf{x}_1,\mathbf{x}_,\dots,\mathbf{x}_N]^T$：表示 N 个 D 维向量组成的矩阵
-   $\mathbf{M}$：表示矩阵；$( w_1,\cdots,w_M )$：表示一个行向量有 $M$ 个元素；**w**= ( $w_1,\cdots,w_M )^T$ 表示对应的列向量。
-   $\mathbf{I}_M$：表示 $M \times M$ 单位阵。
-   $x$：表示元素；$y ( x )$：表示函数；$f [y]$：表示泛函。
-   $g ( x ) =O ( f ( x ))$：表示复杂度。
-   $\mathbb{E}_x [f ( x,y )]$：随机变量$x$对于函数$f ( x,y )$的期望，符号可以简化为$\mathbb{E}[x]$
-   $\mathbb{E}_x [f ( x ) |z]$：随机变量$x$基于变量$z$的条件期望。
-   $\text{var} [ f ( x )]$：随机变量$x$的方差
-   $\text{cov}[\mathbf{x},\mathbf{y}]$：协方差，$cov[\mathbb{x}]$是$cov[\mathbb{x},\mathbb{x}]$的缩写

## 重要的数学公式

 ( 括号内的是公式的编号 )

<!-- TODO:补充 -->
## 书中符号说明

-   ( P xx ) , 代表第 xx 页；
-   ( Ch xx ) , 代表第 xx 章；
-   ( Sec xx ) , 代表第 xx 节；
-   ( Eq xx ) , 代表第 xx 公式；
-   ( Fig xx ) , 代表第 xx 图
