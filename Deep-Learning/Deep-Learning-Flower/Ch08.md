# C08. 深度模型中的优化

Ch04介绍一般的数值优化问题

Ch08关注特定的数值优化问题：寻找神经网络上的一组参数 $\theta$，用于显著降低代价函数 $J(\theta)$，这个代价函数通常包括整个训练集上的性能评估和额外的正则化项。

## 8.1 不同数值优化问题的区别

-   机器学习的数值优化问题是间接的：最小化目标 $J$ 不是问题的目标，问题关注某些性能度量$P$，其定义于测试集上，并且可能是不可解的。因此，只能间接地优化 $P$，即通过降低代价函数 $J(\theta)$ 来提高 $P$ 
    -   训练集上的代价函数的形式化定义：$J(\theta)=\mathbb{E}_{\text{x,y}\sim\hat{p}_\text{data}} L(f(\mathbf{x;\theta}),y)$
        -   $L$ 是每个样本的损失函数
        -   $f(\mathbf{x;\theta})$ 是输入 $\mathbf{x}$ 时所预测的输出
        -   $\hat{p}_\text{data}$ 是经验分布
        -   在监督学习中，$y$ 是目标输出
    -   原始数据集上的代价函数的形式化定义：$J^*(\theta)=\mathbb{E}_{\text{x,y}\sim p_\text{data}} L(f(\mathbf{x;\theta}),y)$
        -   $J^*(\theta)$ ：是问题的真实目标函数
        -   生成原始数据集的分布 $p_\text{data}$ 的期望
-   纯数值优化问题是直接的：即最小化目标 $J$ 就是问题的目标

### 8.1.1 经验风险最小化

将机器学习问题转化为优化问题的方式：最小化训练集上的期望损失。

经验风险(empirical risk)：用训练集上的经验分布 $\hat{p}_\text{data}$ 代替真实分布 $p_\text{data}$。

经验风险最小化(empirical risk minimization)：基于最小化这种平均训练误差的训练过程

经验风险最小化很容易导致过拟合：因为高容量的模型会记住训练集

### 8.1.2 现实情况下的损失函数和优化方法

代理损失函数(surrogate loss function)

-   正确类别的负对数似然函数用于 0-1 损失的替代

代理损失函数与纯优化对比

-   代理损失函数提前终止时导数可能还很大
-   纯优化终止时导数较小

### 8.1.3 批量算法和小批量算法

机器学习算法的目标函数可以分解为训练样本上的求和

-   最大似然估计问题可以在对数空间中分解成各个样本的总和
    $$
    \theta_{ML}=\arg\max_{\theta}\sum_{i=1}^m\log p_{\text{model}}(\mathbf{x}^{(i)},y^{(i)};\theta)
    $$



1.  使用整个训练集的优化算法被称为批量(batch)或者确定性(deterministic)梯度算法
2.  每次只使用单个样本的优化算法称为随机(stochastic)或者在线(online)算法。
3.  使用一个以上而不是全部训练样本的深度学习优化算法称为小批量(minibatch)或小批量随机(minibatch stochastic)算法，统称为随机(stochastic)方法。

小批量的大小设置

-   更大的批量会计算更加精确的梯度估计，但是回报是小于线性的
-   过小的批量无法充分利用多核计算架构
-   如果批量处理中的所有样本可以并行处理，那么内存消耗和批量大小成正比
-   批处理大小通常使用 2 的幂数，取值范围在 32~256 之间，对于某些大模型时可以考虑 16
-   小批量学习过程中加入的噪声可以会产生一定的正则化效果

## 8.2 神经网络优化中的困难

优化问题本身就是一个极其困难的任务。

-   传统的机器学习会小心设计目标函数和约束，以确保优化问题是凸的，从而避免一般优化问题的复杂度
-   深度学习肯定会遇到一般的非凸问题，即使是凸优化问题也面临以下困难
    -   矩阵病态问题
    -   局部极小值
    -   平坦区域(高原、鞍点等等)
    -   斜率悬崖结构导致的梯度爆炸问题
    -   长期依赖导致的梯度消失问题
    -   非精确梯度
    -   局部结构与全局结构之间的弱对应
    -   优化问题存在的理论限制

### 8.2.1 病态问题

Hessian 矩阵 $H$ 的病态问题：在随机梯度下降时会「卡」在某些情况下，此时即使很小的更新步长也会增加代价函数，因此学习率必须收缩以弥补更强的曲率。

### 8.2.2 局部极小值

模型可辨识性(model identifiability)问题：如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨识的。

-   带有隐变量的模型通常是不可辨识的
    -   权重空间对称性(weight space symmetry)：对神经网络的任一隐藏层的 单元 $i$ 、单元 $j$ 的传入权重向量和传出权重向量交换，得到等价模型；如果神经网络有 $m$ 层，每层有 $n$ 个单元，那么会有 $n!^m$ 种排列隐藏单元的方式。这种类型的不可辨识性称为权重空间对称性。
-   带有整流线性单元的网络或者 maxout 的网络是不可辨识的
    -   将传入权重和偏置扩大 $\alpha$ 倍，传出权重扩大 $\frac1\alpha$ 倍，得到等价模型

模型可辨识性问题导致：神经网络代价函数具有非常多甚至不可数无限多的局部极小值，而且这些局部极小值都有相同的代价函数值，因此这些局部极小值不是非凸带来的问题。

学者们猜想：对于足够大的神经网络，大部分局部极小值都具有很小的代价函数，因此找全局最小点不是最重要的，而是需要在参数空间中找到一个代价很小(可能不是最小)的点。

一种排除局部最小值的方法：如果梯度范数没有随着时间缩小到一个微小的值，那么得到的既不是局部极小值，也不是其他形式的临界点。

### 8.2.3 平坦区域(高原、鞍点)

鞍点：在鞍点处，Hessian矩阵同时具有正负特征值。位于正特征值对应的特征向量方向的点比鞍点的代价大，位于负特征值对应的特征向量方向的点比鞍点的代价小，鞍点为代价函数在某个横截面上的局部极小点，也为代价函数某个横截面上的局部极大点。

随机函数

-   低维空间中，局部极小值很常见
-   高维空间中，局部极小值很罕见，鞍点很常见

投影函数($f:\mathbb{R}^n\rightarrow\mathbb{R}$)：鞍点和局部极小值的数目比率的期望随 $n$ 指数级增长

随机函数

-   具有低代价的点更可能是局部极小值
-   具有高代价的点更可能是鞍点
-   具有极高代价的点更可能是局部极大值

鞍点

-   对于只使用梯度信息的一阶优化算法，实验中梯度下降似乎可以在许多情况下逃离鞍点
-   对于牛顿法目标是寻找梯度为零的点，如果没有适当的修改，优化就会跳进鞍点，可以考虑使用无鞍牛顿法，但是对于大型网络效果不好。

### 8.2.4 斜率悬崖结构导致的梯度爆炸

长期时间序列会产生大量的权重相乘，几个较大的权重相乘会导致悬崖结构。

当传统的梯度下降算法更新步长过大时，[Ch10.md](Ch10)启发式梯度截断(gradient clipping)会干涉来减小步长，从而避免越过悬崖区域。

### 8.2.5 长期依赖导致的梯度消失

长期依赖问题：变深的神经网络结构使模型丧失了学习到先前信息的能力，从而使优化变得极其困难。

假设某个计算图中包含一条反复与矩阵 $W$ 相乘的路径，那么 $t$ 步后相当于乘以 $W^t$，对 $W$ 进行特征值分解 $W=V\text{diag}(\lambda)V^{-1}$，得 $W^t=(V\text{diag}(\lambda)V^{-1})^t=V\text{diag}(\lambda)^t V^{-1}$，因此计算图上的梯度会因为 $\text{diag}(\lambda)^t$ 而导致梯度消失或者梯度爆炸问题。

循环网络在各个时间步上使用相同的矩阵 $W$，而前馈网络使用不同的矩阵，因此即使非常深层的前馈网络也能在很大程度上有效地避免梯度消失和梯度爆炸问题。

### 8.2.6 非精确梯度

大多数优化算法的先决条件是知道精确的梯度或者 Hessian 矩阵，但是当目标函数不可解时，只有使用近似梯度代替，或者使用代理损失函数来避免这个问题。

### 8.2.7 局部结构与全局结构之间的弱对应

许多现有研究方法在求解具有困难的全局结构的问题时，旨在寻找良好的初始点，而不是开发非局部范围更新的算法。

基本上所有的可以有效地训练神经网络的学习算法都是基于局部较小更新。

### 8.2.8 传统的优化理论的限制

为神经网络设计的优化算法都有性能限制，因此研究优化算法现实的性能上界是重要目标。

-   大多数神经网络单元输出光滑的连续值，使得局部搜索求解优化可行
-   理论结果表明某些问题是不可解的，但是无法判断哪个问题是不可解的
-   寻找给定规模的网络的一个可行解是困难的，但是使用更大的网络可以找到可接受的解
-   在神经网络训练中，不关注某个函数的精确极小点，只关注将其值下降到足够小以获得一个良好的泛化误差，但是对优化算法进行理论分析判断是否能够实现目标也是困难的

## 8.3 基本算法